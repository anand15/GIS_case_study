# import library
import geopandas as gpd
import pandas as pd
from shapely.ops import nearest_points
import rasterio
import rasterio.mask
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

################################## PART 1 ######################
# calculate the distance of builtup polygon to nearest stream
# Load polygon and line layers

builtup = gpd.read_file("builtup.shp")  # Replace with actual path
streams = gpd.read_file("stream.shp")  # Replace with actual path

f "id" not in builtup.columns:
    builtup["id"] = range(1, len(builtup) + 1)

# modified code for distance to only nearest stream. Not all streams
# Create an empty list to store results
results = []
# Iterate through each built-up polygon
for idx, builtup_feature in builtup.iterrows():
    builtup_geom = builtup_feature.geometry  # Get the polygon geometry

    # Find the index of the nearest stream in the full streams layer
    nearest_stream_idx = streams.geometry.distance(builtup_geom).idxmin()
    nearest_distance = builtup_geom.distance(streams.loc[nearest_stream_idx, "geometry"])
    
    # Retrieve the stream order for the nearest stream
    stream_order = streams.loc[nearest_stream_idx, "ORDER"]

    # Append results with builtup_id, stream order, and nearest distance
    results.append({
        "builtup_id": builtup_feature["id"],  # Change 'id' to the actual column name if needed
        "stream_order": stream_order,
        "distance": nearest_distance
    })

# Convert results to DataFrame and save to a CSV file
df = pd.DataFrame(results)
df.to_csv("builtup_stream_distance.csv", index=False)

###################### PART 2 ########################
# Plotting the distance value
dist_b14= pd.read_csv(r"path\to\distance\csv\area1\year2014") 
dist_b24 = pd.read_csv(r"path\to\distance\csv\area1\year2024")
dist_g14 = pd.read_csv(r"path\to\distance\csv\area2\year2014")
dist_g24 = pd.read_csv(r"path\to\distance\csv\area2\year2024")
dist_u14 = pd.read_csv(r"path\to\distance\csv\area3\year2014")
dist_u24 = pd.read_csvr"path\to\distance\csv\area3\year2034")

df_dict = {
    "dist_b14": dist_b14,
    "dist_b24": dist_b24,
    "dist_g14": dist_g14,
    "dist_g24": dist_g24,
    "dist_u14": dist_u14,
    "dist_u24": dist_u24
}

min_dis = []
max_dis = []

for df in df_list:
    temp_min = df['distance'].min()
    temp_max = df['distance'].max()
    min_dis.append(temp_min)
    max_dis.append(temp_max)

print(min(min_dis))
print(max(max_dis))

bins = [0, 500, 1000, 1500]
labels = ['0-500', '500-1000', '1000-1500']

combined_built_dist = pd.DataFrame()



for name, df in df_dict.items():
    # Create a new category column using pd.cut
    df['category'] = pd.cut(df['distance'], bins=bins, labels=labels, right=False)
    
    # Assign the name as a string identifier to the 'type' column.
    df['type'] = name
    
    # Group by 'type', 'location', and 'date', then count the number of built-up features.
    built_counts = df.groupby(['type', 'category', 'stream_order']).size().reset_index(name='built_count')
    
    # Append the results to the combined DataFrame.
    combined_built_dist = pd.concat([combined_built_dist, built_counts], ignore_index=True)


combined_built_dist['year'] = combined_built_dist['type'].str[-2:].astype(int) + 2000

# Use regex to extract the character following the underscore
combined_built_dist['town_code'] = combined_built_dist['type'].str.extract(r'_(.)')[0]

# Define a mapping from code letters to full city names
code_to_town = {'b': 'Barkot', 'g': 'Gangotri', 'u': 'Uttarkashi'}

# Map the extracted code to the corresponding city name
combined_built_dist['town'] = combined_built_dist['town_code'].map(code_to_town)

# Optionally, drop the helper column
df = combined_built_dist.drop(columns='town_code')

combined_built_dist.to_csv("combined_builtup_distance.csv")

combined_built_dist.head(1)

# Create separate plots for each unique town (location)
for town in combined_built_dist['town'].unique():
    df_town = combined_built_dist[combined_built_dist['town'] == town]
    
    # Create a facet grid using catplot; facets (columns) are determined by stream_order.
    g = sns.catplot(
        data=df_town,
        x='category',
        y='built_count',
        hue='year',
        kind='bar',
        col='stream_order',
        col_wrap=3,
        errorbar=("ci", 95)
        
    )
    
    # Adjust the title and layout for clarity
    g.fig.suptitle(f"Number of built-up by Distance Category for {town}", fontsize=16)
    g.set_axis_labels("Distance Category", "Number of Builtup")
    g.set_titles("Stream Order: {col_name}")
    plt.subplots_adjust(top=0.85)  # Adjust to give space for the main title
    plt.show()   


###################### PART 3 ##########################
# calculate the value of maximum slope for each polygon of builtup

# Load built-up polygon layer
builtup = gpd.read_file("builtup.shp")  # Replace with actual path
slope_raster = "slope.tif"  # Path to slope raster file

# Ensure the built-up layer has an ID field
if "id" not in builtup.columns:
    builtup["id"] = range(1, len(builtup) + 1)  # Assigns unique IDs starting from 1

# Open the slope raster to get its CRS
with rasterio.open(slope_raster) as src:
    raster_crs = src.crs  # Get the raster CRS

# Ensure the built-up layer has the same CRS as the raster
if builtup.crs != raster_crs:
    print(f"Reprojecting built-up layer from {builtup.crs} to {raster_crs}")
    builtup = builtup.to_crs(raster_crs)

# Initialize results list
results = []

# Open the slope raster
with rasterio.open(slope_raster) as src:
    # Iterate over each built-up polygon
    for idx, row in builtup.iterrows():
        polygon_geom = [row.geometry]  # Convert polygon to list format for rasterio.mask
        
        # Clip the raster using the polygon
        try:
            out_image, out_transform = rasterio.mask.mask(src, polygon_geom, crop=True, nodata=np.nan)
            out_image = out_image[0]  # Extract the single band

            # Remove nodata values before computing max slope
            valid_values = out_image[~np.isnan(out_image)]

            if valid_values.size > 0:
                max_slope = np.max(valid_values)  # Compute the maximum slope
            else:
                max_slope = np.nan  # If no valid values exist

            # Store result
            results.append({"builtup_id": row["id"], "max_slope": max_slope})

        except Exception as e:
            print(f"Error processing polygon {row['id']}: {e}")
            results.append({"builtup_id": row["id"], "max_slope": np.nan})

# Convert results to DataFrame
df = pd.DataFrame(results)

# Save to CSV
df.to_csv("builtup_max_slope.csv", index=False)

######################### PART 4 ########################
# summary statistics for slope values calcualted earlier
# import all files containing the slope values

town1_2014 = pd.read_csv("town1_2014_max_slope.csv")
town1_2024 = pd.read_csv("town1_2024_max_slope.csv")
town2_2014 = pd.read_csv("town2_2014_max_slope.csv")
town2_2024 = pd.read_csv("town2_2024_max_slope.csv")
town3_2014 = pd.read_csv("town3_2014_max_slope.csv")
town4_2024 = pd.read_csv("town3_2024_max_slope.csv")

# Create a dictionary of datasets
datasets = {
    "town1_2014": town1_2014,
    "town1_2024": town1_2024,
    "town2_2014": town2_2014,
    "town2_2024": town2_2024,
    "town3_2014": town3_2014,
    "town3_2024": town3_2024
}

# Compute summary statistics for each dataset
summary_list = []
for name, df in datasets.items():
    if "max_slope" in df.columns:  # Ensure max_slope column exists
        summary = df["max_slope"].describe().to_dict()
        summary["location_year"] = name  # Add identifier
        summary_list.append(summary)

# Convert to DataFrame
slope_summary = pd.DataFrame(summary_list)

slope_summary.to_csv("slope_summary.csv")

########################### PART 5 ###########################
# KDE plots for distribution of slope values
# we need to import the slope file for year 2014 and 2024 for a town and then repeat the process for other towns

a = pd.read_csv("town1_2014_max_slope.csv")
b = pd.read_csv("town2_2024_max_slope.csv")

# Add year column
a["year"] = "2014"
b["year"] = "2024"

# Combine datasets
df = pd.concat([a, b], ignore_index=True)

# Create the KDE plot with separate lines for 2014 and 2024 using a loop
plt.figure(figsize=(10, 6))

# Define colors for each year
colors = {"2014": "blue", "2024": "red"}

# Loop through each year and plot KDE
for year in ["2014", "2024"]:
    sns.kdeplot(
        data=df[df["year"] == year],  # Filter data for the given year
        x="max_slope",
        color=colors[year],
        label=year,
        linewidth=2
    )

# Set labels and title
plt.xlabel("Maximum Slope")
plt.ylabel("Density")
plt.title("Distribution of Maximum Slope for Built-Up Areas")

# Show legend and plot
plt.legend(title="Year")
plt.show()
