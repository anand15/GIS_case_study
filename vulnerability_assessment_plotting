# import library
import geopandas as gpd
import pandas as pd
from shapely.ops import nearest_points
import rasterio
import rasterio.mask
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

################################## PART 1 ######################
# calculate the distance of builtup polygon with each stream order
# Load polygon and line layers

builtup = gpd.read_file("builtup.shp")  # Replace with actual path
streams = gpd.read_file("stream.shp")  # Replace with actual path

# Ensure both layers have the same CRS
builtup = builtup.to_crs(streams.crs)

if "id" not in builtup.columns:
    builtup["id"] = range(1, len(builtup) + 1)

# Check if stream layer has a column indicating stream order
#if "stream_order" not in streams.columns:
 #   raise ValueError("Stream layer must have a 'stream_order' field.")

# Create an empty list to store results
results = []

# Iterate over unique stream orders
for order in streams["ORDER"].unique():
    # Filter stream layer by stream order
    stream_subset = streams[streams["ORDER"] == order]

    # Iterate through each built-up polygon
    for idx, builtup_feature in builtup.iterrows():
        builtup_geom = builtup_feature.geometry  # Get the polygon geometry

        # Find the nearest stream segment from the subset
        nearest_stream = stream_subset.geometry.distance(builtup_geom).idxmin()
        nearest_distance = builtup_geom.distance(stream_subset.loc[nearest_stream, "geometry"])

        # Append to results list
        results.append({
            "builtup_id": builtup_feature["id"],  # Change 'id' to match the actual column name
            "stream_order": order,
            "distance": nearest_distance
        })

# Convert results to DataFrame
df = pd.DataFrame(results)

# Save the result to a CSV file
df.to_csv("builtup_stream_distance.csv", index=False)

###################### PART 2 ########################
# summary statistics for stream distances
# Here df is the dataframe containing all calculated distances in the previous steps

summary_2014 = df[df["year"] == "2014"].groupby("stream_order")["distance"].describe()
summary_2024 = df[df["year"] == "2024"].groupby("stream_order")["distance"].describe()

# Merging summaries for comparison
summary_stats = summary_2014.join(summary_2024, lsuffix="_2014", rsuffix="_2024")

# Selecting relevant statistics to present
summary_stats = summary_stats[["mean_2014", "mean_2024", "std_2014", "std_2024", "min_2014", "min_2024", "max_2014", "max_2024"]]

summary_stats.to_csv("uttarkashi_stream.csv")

################ PART 3 #####################
# KDE plots of stream distances
# we need to import the distance file for 2014 and 2024 for a town and then repeat this process for other towns

a = pd.read_csv("town1_2014_stream_distance.csv")
b = pd.read_csv("town1_2024_stream_distance.csv")


# Add year column
a["year"] = "2014"
b["year"] = "2024"

# Combine datasets
df = pd.concat([a, b], ignore_index=True)

import matplotlib.pyplot as plt
import seaborn as sns

# Set up FacetGrid to create separate density plots for each stream order
g = sns.FacetGrid(df, col="stream_order", col_wrap=3, sharex=True, sharey=True)

# Plot overlapping density plots for 2014 and 2024
for ax, (order, subset) in zip(g.axes.flat, df.groupby("stream_order")):
    sns.kdeplot(subset[subset["year"] == "2014"]["distance"], color="blue", label="2014", ax=ax, linewidth=2)
    sns.kdeplot(subset[subset["year"] == "2024"]["distance"], color="red", label="2024", ax=ax, linewidth=2)
    ax.legend(title="Year")  # Ensure correct legend

# Set labels and titles
g.set_axis_labels("Distance to Stream", "Density")
g.set_titles("Stream Order {col_name}")

# Add an overall title
plt.subplots_adjust(top=0.9)  # Adjust space for the title
g.fig.suptitle("Uttarkashi", fontsize=14)

# Show the plot
plt.show()

###################### PART 4 ##########################
# calculate the value of maximum slope for each polygon of builtup

# Load built-up polygon layer
builtup = gpd.read_file("builtup.shp")  # Replace with actual path
slope_raster = "slope.tif"  # Path to slope raster file

# Ensure the built-up layer has an ID field
if "id" not in builtup.columns:
    builtup["id"] = range(1, len(builtup) + 1)  # Assigns unique IDs starting from 1

# Open the slope raster to get its CRS
with rasterio.open(slope_raster) as src:
    raster_crs = src.crs  # Get the raster CRS

# Ensure the built-up layer has the same CRS as the raster
if builtup.crs != raster_crs:
    print(f"Reprojecting built-up layer from {builtup.crs} to {raster_crs}")
    builtup = builtup.to_crs(raster_crs)

# Initialize results list
results = []

# Open the slope raster
with rasterio.open(slope_raster) as src:
    # Iterate over each built-up polygon
    for idx, row in builtup.iterrows():
        polygon_geom = [row.geometry]  # Convert polygon to list format for rasterio.mask
        
        # Clip the raster using the polygon
        try:
            out_image, out_transform = rasterio.mask.mask(src, polygon_geom, crop=True, nodata=np.nan)
            out_image = out_image[0]  # Extract the single band

            # Remove nodata values before computing max slope
            valid_values = out_image[~np.isnan(out_image)]

            if valid_values.size > 0:
                max_slope = np.max(valid_values)  # Compute the maximum slope
            else:
                max_slope = np.nan  # If no valid values exist

            # Store result
            results.append({"builtup_id": row["id"], "max_slope": max_slope})

        except Exception as e:
            print(f"Error processing polygon {row['id']}: {e}")
            results.append({"builtup_id": row["id"], "max_slope": np.nan})

# Convert results to DataFrame
df = pd.DataFrame(results)

# Save to CSV
df.to_csv("builtup_max_slope.csv", index=False)

######################### PART 5 ########################
# summary statistics for slope values calcualted earlier
# import all files containing the slope values

town1_2014 = pd.read_csv("town1_2014_max_slope.csv")
town1_2024 = pd.read_csv("town1_2024_max_slope.csv")
town2_2014 = pd.read_csv("town2_2014_max_slope.csv")
town2_2024 = pd.read_csv("town2_2024_max_slope.csv")
town3_2014 = pd.read_csv("town3_2014_max_slope.csv")
town4_2024 = pd.read_csv("town3_2024_max_slope.csv")

# Create a dictionary of datasets
datasets = {
    "town1_2014": town1_2014,
    "town1_2024": town1_2024,
    "town2_2014": town2_2014,
    "town2_2024": town2_2024,
    "town3_2014": town3_2014,
    "town3_2024": town3_2024
}

# Compute summary statistics for each dataset
summary_list = []
for name, df in datasets.items():
    if "max_slope" in df.columns:  # Ensure max_slope column exists
        summary = df["max_slope"].describe().to_dict()
        summary["location_year"] = name  # Add identifier
        summary_list.append(summary)

# Convert to DataFrame
slope_summary = pd.DataFrame(summary_list)

slope_summary.to_csv("slope_summary.csv")

########################### PART 6 ###########################
# KDE plots for distribution of slope values
# we need to import the slope file for year 2014 and 2024 for a town and then repeat the process for other towns

a = pd.read_csv("town1_2014_max_slope.csv")
b = pd.read_csv("town2_2024_max_slope.csv")

# Add year column
a["year"] = "2014"
b["year"] = "2024"

# Combine datasets
df = pd.concat([a, b], ignore_index=True)

# Create the KDE plot with separate lines for 2014 and 2024 using a loop
plt.figure(figsize=(10, 6))

# Define colors for each year
colors = {"2014": "blue", "2024": "red"}

# Loop through each year and plot KDE
for year in ["2014", "2024"]:
    sns.kdeplot(
        data=df[df["year"] == year],  # Filter data for the given year
        x="max_slope",
        color=colors[year],
        label=year,
        linewidth=2
    )

# Set labels and title
plt.xlabel("Maximum Slope")
plt.ylabel("Density")
plt.title("Distribution of Maximum Slope for Built-Up Areas")

# Show legend and plot
plt.legend(title="Year")
plt.show()
